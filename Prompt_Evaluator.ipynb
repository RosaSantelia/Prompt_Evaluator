{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1kj4gn66DaluXbZM3R2i-Oc24HLxoHpk-","timestamp":1747680215887},{"file_id":"1SR-Uby2DzIwhFXDia4dgOlmBvp2551gq","timestamp":1747675685177}],"authorship_tag":"ABX9TyPTapsXzUC5duSY1Kif8IXS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Import and mount Google Drive to access saved files\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Install all necessary libraries\n","!pip install nltk rouge-score sentence-transformers matplotlib transformers torch scikit-learn detoxify\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# BLEU score to evaluate textual similarity between two sentences\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","\n","# Detoxify is used to measure the toxicity of generated text\n","from detoxify import Detoxify\n","\n","# To get semantic embeddings of texts\n","from sentence_transformers import SentenceTransformer\n","\n","# Cosine similarity calculation between embedding vectors\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# Path of the CSV file containing prompts to evaluate\n","csv_path = '/content/drive/MyDrive/prompts_to_evaluate.csv'  # Change here if needed\n","\n","# Load data from CSV into a DataFrame\n","df = pd.read_csv(csv_path)\n","print(df.head())  # Print first rows to check data\n","\n","# Function to compute BLEU score between reference and generated text\n","def compute_bleu(reference, generated):\n","    # Simply tokenize by splitting, can be improved with more precise tokenizers\n","    reference_tokens = reference.lower().split()\n","    generated_tokens = generated.lower().split()\n","    # Apply smoothing to avoid issues with very short or rare sentences\n","    smoothie = SmoothingFunction().method4\n","    return sentence_bleu([reference_tokens], generated_tokens, smoothing_function=smoothie)\n","\n","# Function to calculate toxicity score using Detoxify\n","def compute_toxicity(text):\n","    # Use 'original' model for a standard toxicity evaluation\n","    result = Detoxify('original').predict(text)\n","    # Extract the toxicity score\n","    return result['toxicity']\n","\n","# Compute BLEU score and toxicity for each row in the DataFrame\n","df['BLEU'] = df.apply(lambda row: compute_bleu(row['reference'], row['generated']), axis=1)\n","df['Toxicity'] = df['generated'].apply(compute_toxicity)\n","\n","# Initialize model to convert sentences into numerical vectors (embeddings)\n","model = SentenceTransformer('all-mpnet-base-v2')\n","\n","# Function to compute semantic similarity (cosine) between reference and generated text\n","def compute_semantic_similarity(reference, generated):\n","    embeddings = model.encode([reference, generated])  # Get the embeddings\n","    sim = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]  # Calculate cosine similarity\n","    return sim\n","\n","# Apply function on all rows to compute semantic similarity\n","df['Semantic_Similarity'] = df.apply(lambda row: compute_semantic_similarity(row['reference'], row['generated']), axis=1)\n","\n","# Display the DataFrame with a color gradient depending on the metric values\n","display(df.style.background_gradient(cmap='coolwarm', subset=['BLEU', 'Toxicity', 'Semantic_Similarity']))\n","\n","# Save results to a CSV file for future analysis or sharing\n","output_path = \"prompt_evaluation_results.csv\"\n","df.to_csv(output_path, index=False)\n","\n","# Plot a bar chart showing all three metrics for each prompt\n","plt.figure(figsize=(12,6))\n","plt.bar(df.index - 0.2, df['BLEU'], width=0.2, label='BLEU', color='skyblue')\n","plt.bar(df.index, df['Semantic_Similarity'], width=0.2, label='Semantic Similarity', color='lightgreen')\n","plt.bar(df.index + 0.2, df['Toxicity'], width=0.2, label='Toxicity', color='salmon')\n","plt.xlabel(\"Prompt #\")\n","plt.ylabel(\"Score\")\n","plt.title(\"Prompt Evaluation - BLEU, Semantic Similarity, Toxicity\")\n","plt.ylim(0, 1)  # Limit y-axis from 0 to 1 for metric consistency\n","plt.xticks(df.index, labels=[f\"Prompt {i+1}\" for i in df.index])\n","plt.legend()\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n","\n"],"metadata":{"id":"TfGZqkvohmpO"},"execution_count":null,"outputs":[]}]}